{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Classification\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "5216ea39-0c0b-48dc-8335-ffdb46709bd8",
       "rows": [
        [
         "0",
         "-0.1898389674095912",
         "1.0501663945841435"
        ],
        [
         "1",
         "-0.1325639327187821",
         "0.9827414728017192"
        ],
        [
         "2",
         "-0.3942632745368248",
         "1.2217913696169012"
        ],
        [
         "3",
         "-0.2686371965967205",
         "1.2499466167967468"
        ],
        [
         "4",
         "1.9482695750646744",
         "-0.4783181635813117"
        ],
        [
         "5",
         "-0.11663098136887035",
         "0.9872966004772346"
        ],
        [
         "6",
         "-0.7694217678658064",
         "0.2179473988185585"
        ],
        [
         "7",
         "1.5963807179650296",
         "-0.4136408388201948"
        ],
        [
         "8",
         "-1.036208712553231",
         "0.8060526170448603"
        ],
        [
         "9",
         "0.6472496073746368",
         "-0.5381337729655779"
        ],
        [
         "10",
         "0.987384686574552",
         "-0.742238317654856"
        ],
        [
         "11",
         "-0.05547334009542221",
         "1.0174961104757287"
        ],
        [
         "12",
         "0.6865225067146861",
         "-0.48657116226136954"
        ],
        [
         "13",
         "0.40583204446352966",
         "-0.5611662706815232"
        ],
        [
         "14",
         "-0.6561005618800594",
         "0.8363734397713739"
        ],
        [
         "15",
         "0.14414370742131255",
         "0.916713582514424"
        ],
        [
         "16",
         "1.9748165653027092",
         "-0.03749797741960032"
        ],
        [
         "17",
         "2.04307348445265",
         "0.0087960331797311"
        ],
        [
         "18",
         "0.987122941928949",
         "0.9992444700877808"
        ],
        [
         "19",
         "0.5619124197582888",
         "0.8676817551775247"
        ],
        [
         "20",
         "0.1989909854087843",
         "-0.5117335210068844"
        ],
        [
         "21",
         "0.8384472255074723",
         "0.7590504364936842"
        ],
        [
         "22",
         "0.9377467203730866",
         "0.0039735169920736835"
        ],
        [
         "23",
         "0.4084449884131124",
         "0.0704520991330084"
        ],
        [
         "24",
         "0.8058520751496657",
         "0.5744076068750237"
        ],
        [
         "25",
         "0.5646707313380992",
         "-0.4933490096901405"
        ],
        [
         "26",
         "1.6292085151782496",
         "0.1773034499058695"
        ],
        [
         "27",
         "0.7034230129065833",
         "-0.1798320083527195"
        ],
        [
         "28",
         "0.35449514806473553",
         "-0.40577749222340714"
        ],
        [
         "29",
         "0.3997941309971588",
         "0.05333514791391003"
        ],
        [
         "30",
         "1.1352276832526766",
         "0.2338136552026678"
        ],
        [
         "31",
         "-0.6660745355529283",
         "0.794849274732773"
        ],
        [
         "32",
         "0.6387706602912584",
         "0.7340598665305759"
        ],
        [
         "33",
         "-0.7348399766687647",
         "0.7119044262081908"
        ],
        [
         "34",
         "0.36324972730779614",
         "0.26784561001165075"
        ],
        [
         "35",
         "0.8108084438543012",
         "0.6183810247620716"
        ],
        [
         "36",
         "2.2866861793014683",
         "-0.180600655733106"
        ],
        [
         "37",
         "1.0912264623299615",
         "-0.31675451470879207"
        ],
        [
         "38",
         "0.04947820048006432",
         "0.4912915609711612"
        ],
        [
         "39",
         "0.8025011187184768",
         "-0.45307391895576066"
        ],
        [
         "40",
         "0.11826703010021432",
         "-0.1764080976234542"
        ],
        [
         "41",
         "0.550223115227863",
         "0.9455781719104579"
        ],
        [
         "42",
         "0.984357999077352",
         "0.3754380611552261"
        ],
        [
         "43",
         "0.6600442400901954",
         "-0.07936179805862019"
        ],
        [
         "44",
         "0.5031466639170262",
         "-0.39651409439860646"
        ],
        [
         "45",
         "1.8018963119975409",
         "-0.5071456716381073"
        ],
        [
         "46",
         "-0.448163627532513",
         "1.0831169043798328"
        ],
        [
         "47",
         "1.3388667334517947",
         "-0.04795315801012051"
        ],
        [
         "48",
         "1.8350455406332415",
         "0.14716971497529832"
        ],
        [
         "49",
         "1.6681895659314678",
         "-0.13846509063212925"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 160
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.189839</td>\n",
       "      <td>1.050166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.132564</td>\n",
       "      <td>0.982741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.394263</td>\n",
       "      <td>1.221791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.268637</td>\n",
       "      <td>1.249947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.948270</td>\n",
       "      <td>-0.478318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1.966937</td>\n",
       "      <td>-0.230039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.919107</td>\n",
       "      <td>0.655677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-0.628637</td>\n",
       "      <td>0.402392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.355167</td>\n",
       "      <td>0.562167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>-0.770417</td>\n",
       "      <td>0.535014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1\n",
       "0   -0.189839  1.050166\n",
       "1   -0.132564  0.982741\n",
       "2   -0.394263  1.221791\n",
       "3   -0.268637  1.249947\n",
       "4    1.948270 -0.478318\n",
       "..        ...       ...\n",
       "155  1.966937 -0.230039\n",
       "156  0.919107  0.655677\n",
       "157 -0.628637  0.402392\n",
       "158  0.355167  0.562167\n",
       "159 -0.770417  0.535014\n",
       "\n",
       "[160 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import datasets:\n",
    "\n",
    "x_train = pd.read_csv('X_train.csv', header=None)\n",
    "y_train = pd.read_csv('Y_train.csv', header=None)\n",
    "x_test = pd.read_csv('X_test.csv', header=None)\n",
    "y_test = pd.read_csv('Y_test.csv', header=None)\n",
    "\n",
    "# verify data:\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a Feedforward Neural Nerwork (FNN) in PyTorch.\n",
    "    # a. Input size is 2, output size is 1\n",
    "    # b. Use ReLU activation for hidden layers\n",
    "    # c. Use sigmoid activation for output layer\n",
    "    # d. Use Binary Cross Entropy (BCELoss) as the training objective\n",
    "    # e. Use the Adam optimizer.\n",
    "\n",
    "# Train and evaluate model with different architectures: \n",
    "    # a. 1 hidden layer with 16 neurons\n",
    "    # b. 2 hidden layers, 16 neurons each\n",
    "    # c. 3 hidden layers, 16 neurons each\n",
    "    # d. for each model, compute and report the training and testing accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.2856\n",
      "Epoch [200/1000], Loss: 0.2522\n",
      "Epoch [300/1000], Loss: 0.2249\n",
      "Epoch [400/1000], Loss: 0.1953\n",
      "Epoch [500/1000], Loss: 0.1680\n",
      "Epoch [600/1000], Loss: 0.1482\n",
      "Epoch [700/1000], Loss: 0.1336\n",
      "Epoch [800/1000], Loss: 0.1244\n",
      "Epoch [900/1000], Loss: 0.1170\n",
      "Epoch [1000/1000], Loss: 0.1114\n",
      "Training Accuracy: 0.9688\n",
      "Testing Accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "# a. 1 hidden layer with 16 neurons\n",
    "# Define the FNN class \n",
    "class FNN(nn.Module):\n",
    "    def __init__(self, hidden_size= 16, input_size=2, output_size=1):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) # Hidden Layer 1\n",
    "        self.relu = nn.ReLU() # Activation function for Hidden Layer 1\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size) # Output layer\n",
    "        self.sigmoid = nn.Sigmoid() # Activation function for Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "# Convert data to PyTorch tensors\n",
    "x_train_tensor = torch.tensor(x_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "x_test_tensor = torch.tensor(x_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "# Create the model\n",
    "model = FNN(hidden_size=16, input_size=2, output_size=1)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 1000\n",
    "batch_size = 32\n",
    "num_batches = len(x_train_tensor) // batch_size\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(num_batches):\n",
    "        # Get the batch data\n",
    "        x_batch = x_train_tensor[i*batch_size:(i+1)*batch_size]\n",
    "        y_batch = y_train_tensor[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "with torch.no_grad():\n",
    "    y_train_pred = model(x_train_tensor)\n",
    "    y_train_pred = (y_train_pred > 0.5).float()  # Convert probabilities to binary predictions\n",
    "    train_accuracy = (y_train_pred.eq(y_train_tensor).sum().item()) / len(y_train_tensor)\n",
    "print(f'Training Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "with torch.no_grad():\n",
    "    y_pred = model(x_test_tensor)\n",
    "    y_pred = (y_pred > 0.5).float()  # Convert probabilities to binary predictions\n",
    "    accuracy = (y_pred.eq(y_test_tensor).sum().item()) / len(y_test_tensor)\n",
    "\n",
    "print(f'Testing Accuracy: {accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.2314\n",
      "Epoch [200/1000], Loss: 0.1352\n",
      "Epoch [300/1000], Loss: 0.1110\n",
      "Epoch [400/1000], Loss: 0.1071\n",
      "Epoch [500/1000], Loss: 0.1070\n",
      "Epoch [600/1000], Loss: 0.1077\n",
      "Epoch [700/1000], Loss: 0.1074\n",
      "Epoch [800/1000], Loss: 0.1066\n",
      "Epoch [900/1000], Loss: 0.1040\n",
      "Epoch [1000/1000], Loss: 0.1016\n",
      "Training Accuracy: 0.9625\n",
      "Testing Accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "# b. 2 hidden layers with 16 neurons\n",
    "# Define the FNN class \n",
    "class FNN(nn.Module):\n",
    "    def __init__(self, hidden_size= 16, input_size=2, output_size=1):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) # Hidden Layer 1\n",
    "        self.relu = nn.ReLU() # Activation function for Hidden Layer 1\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size) # Hidden Layer 2\n",
    "        self.relu = nn.ReLU() # Activation function for Hidden Layer 2\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size) # Output layer\n",
    "        self.sigmoid = nn.Sigmoid() # Activation function for Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)  # Apply ReLU activation to the second hidden layer\n",
    "        x = self.fc3(x)  # Pass through the third layer\n",
    "        x = self.sigmoid(x)  # Apply sigmoid activation to the output layer\n",
    "        return x\n",
    "    \n",
    "# Convert data to PyTorch tensors\n",
    "x_train_tensor = torch.tensor(x_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "x_test_tensor = torch.tensor(x_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "# Create the model\n",
    "model = FNN(hidden_size=16, input_size=2, output_size=1)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 1000\n",
    "batch_size = 32\n",
    "num_batches = len(x_train_tensor) // batch_size\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(num_batches):\n",
    "        # Get the batch data\n",
    "        x_batch = x_train_tensor[i*batch_size:(i+1)*batch_size]\n",
    "        y_batch = y_train_tensor[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "with torch.no_grad():\n",
    "    y_train_pred = model(x_train_tensor)\n",
    "    y_train_pred = (y_train_pred > 0.5).float()  # Convert probabilities to binary predictions\n",
    "    train_accuracy = (y_train_pred.eq(y_train_tensor).sum().item()) / len(y_train_tensor)\n",
    "print(f'Training Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "with torch.no_grad():\n",
    "    y_pred = model(x_test_tensor)\n",
    "    y_pred = (y_pred > 0.5).float()  # Convert probabilities to binary predictions\n",
    "    accuracy = (y_pred.eq(y_test_tensor).sum().item()) / len(y_test_tensor)\n",
    "\n",
    "print(f'Testing Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.2161\n",
      "Epoch [200/1000], Loss: 0.1380\n",
      "Epoch [300/1000], Loss: 0.1322\n",
      "Epoch [400/1000], Loss: 0.1331\n",
      "Epoch [500/1000], Loss: 0.1320\n",
      "Epoch [600/1000], Loss: 0.1297\n",
      "Epoch [700/1000], Loss: 0.1268\n",
      "Epoch [800/1000], Loss: 0.1242\n",
      "Epoch [900/1000], Loss: 0.1226\n",
      "Epoch [1000/1000], Loss: 0.1211\n",
      "Training Accuracy: 0.9688\n",
      "Testing Accuracy: 0.9750\n"
     ]
    }
   ],
   "source": [
    "# c. 3 hidden layers with 16 neurons\n",
    "# Define the FNN class \n",
    "class FNN(nn.Module):\n",
    "    def __init__(self, hidden_size= 16, input_size=2, output_size=1):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) # Hidden Layer 1\n",
    "        self.relu = nn.ReLU() # Activation function for Hidden Layer 1\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size) # Hidden Layer 2\n",
    "        self.relu = nn.ReLU() # Activation function for Hidden Layer 2\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size) # Hidden Layer 3\n",
    "        self.relu = nn.ReLU() # Activation function for Hidden Layer 3\n",
    "        self.fc4 = nn.Linear(hidden_size, output_size) # Output layer\n",
    "        self.sigmoid = nn.Sigmoid() # Activation function for Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)  # Apply ReLU activation to the second hidden layer\n",
    "        x = self.fc3(x)  # Pass through the third layer\n",
    "        x = self.relu(x)  # Apply ReLU activation to the third hidden layer\n",
    "        x = self.fc4(x) # Pass through output layer\n",
    "        x = self.sigmoid(x)  # Apply sigmoid activation to the output layer\n",
    "        return x\n",
    "    \n",
    "# Convert data to PyTorch tensors\n",
    "x_train_tensor = torch.tensor(x_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "x_test_tensor = torch.tensor(x_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "# Create the model\n",
    "model = FNN(hidden_size=16, input_size=2, output_size=1)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 1000\n",
    "batch_size = 32\n",
    "num_batches = len(x_train_tensor) // batch_size\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(num_batches):\n",
    "        # Get the batch data\n",
    "        x_batch = x_train_tensor[i*batch_size:(i+1)*batch_size]\n",
    "        y_batch = y_train_tensor[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "with torch.no_grad():\n",
    "    y_train_pred = model(x_train_tensor)\n",
    "    y_train_pred = (y_train_pred > 0.5).float()  # Convert probabilities to binary predictions\n",
    "    train_accuracy = (y_train_pred.eq(y_train_tensor).sum().item()) / len(y_train_tensor)\n",
    "print(f'Training Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "with torch.no_grad():\n",
    "    y_pred = model(x_test_tensor)\n",
    "    y_pred = (y_pred > 0.5).float()  # Convert probabilities to binary predictions\n",
    "    accuracy = (y_pred.eq(y_test_tensor).sum().item()) / len(y_test_tensor)\n",
    "\n",
    "print(f'Testing Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
